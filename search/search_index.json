{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Pentaho Data Catalog overview","text":"<p>Pentaho Data Catalog rapidly ingests, profiles, and meticulously curates structured and unstructured data through a combination of automation and machine learning. This process involves data fingerprinting and the application of metadata rules to provide contextualization aligned with the business's terminology as documented in the business glossary.</p>"},{"location":"#ai-driven-discovery","title":"AI-driven discovery","text":"<p>Data Catalog uses unique data fingerprinting to automate discovery and classification of structured, semi-structured, and unstructured data.</p>"},{"location":"#user-interface","title":"User interface","text":"<p>Data Catalog's interactive user interface provides a customized user experience for the business role of every user, promoting rich content authoring and resource knowledge.</p>"},{"location":"#data-canvas","title":"Data Canvas","text":"<p>Data Catalog gives users access to the file and field-level metadata available for the entire catalog of data assets. In addition, for the assets that each user has authorization to view, the Data Catalog displays a rich view of data-based details such as minimum, maximum, and most frequent values. Data Catalog users can add their own information to the catalog in the form of descriptions and custom metadata designed for their organization. Use the Data Canvas to explore and investigate your data. Here, you can find detailed insights into resource metadata to help you understand and clarify practical applications.</p> <p></p>"},{"location":"#galaxy-view","title":"Galaxy view","text":"<p>In Data Catalog, you can use the Galaxy view feature to quickly view the structure of your data and its details. Galaxy view is especially useful when you want to view information that is not easily visualized using the navigation tree in the Data Canvas.</p> <p></p> <p>In business glossary, you can use the Galaxy view feature to visualize and explore business terms and their relationships and to understand how terms are interconnected. You can also quickly identify related terms, synonyms, and hierarchies within specific domains or categories, enhancing their understanding of the glossary's structure.</p>"},{"location":"#business-glossary","title":"Business glossary","text":"<p>Data Catalog lets you build or import a taxonomy of business terms in a \u200bglossary and organized into domains and categories and establish relationships between terms. Data Catalog distributes these terms to similar data across the cluster, producing a powerful index for business language searches. It lets business users find the right data quickly to understand the meaning and quality of the data at a glance. Access control User profiles, roles, and access restrictions combine to deny or grant metadata access to users.</p>"},{"location":"#user-roles","title":"User roles","text":"<p>Assigning roles to Data Catalog users lets administrators exercise role-based functional and access control for those users, such as who can assign a business term to data and who can update a business rule. In addition, you can use roles to establish access control over Data Catalog resources at the data source level. Roles also incorporate a set of predefined access levels that define which features of the catalog are available to different users.</p>"},{"location":"#architecture","title":"Architecture","text":"<p>The following diagram provides an overview of Data Catalog's architectural components across the distributed application.</p> <p></p>"},{"location":"#pentaho-data-storage-optimizer","title":"Pentaho Data Storage Optimizer","text":"<p>If you wish, you can install Pentaho Data Storage Optimizer to use with Data Catalog.</p> <p>Data Storage Optimizer is an intelligent data storage tiering solution that reduces operating costs and gives you seamless access to Hadoop data with S3 compatible object storage like Hitachi Content Platform.</p> <p>For more information on Pentaho Data Storage Optimizer, see Pentaho Data Storage Optimizer document.</p> <p>To install Data Storage Optimizer, see the Install chapter of the Pentaho Data Storage Optimizer document.</p> <p>You can either install Data Storage Optimizer when you install Data Catalog, or if you already have Data Catalog 10.0.1 installed, you can enable Data Storage Optimizer.</p>"},{"location":"admonitions/","title":"Admonitions","text":"<p>This is an example of an adominition with a title:</p> <p>Title of the callout</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Collapsible callout:</p> Collapsible callout <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"code-examples/","title":"Code examples","text":"add_numbers.py<pre><code># Function to add two numbers\ndef add_two_numbers(num1, num2):\n    return num1 + num2\n\n# Example usage\nresult = add_two_numbers(5, 3)\nprint('The sum is:', result)\n</code></pre>"},{"location":"code-examples/#highlight-lines","title":"Highlight Lines","text":"<p>To highlight lines type py hl_lines=\"2-4\".</p> <p>Here is another codeblock to show this:</p> code-examples.md<pre><code>// Function to concatenate two strings\nfunction concatenateStrings(str1, str2) {\n  return str1 + str2;\n}\n\n// Example usage\nconst result = concatenateStrings(\"Hello, \", \"World!\");\nconsole.log(\"The concatenated string is:\", result);\n</code></pre>"},{"location":"contents-tab/","title":"Contents tab","text":""},{"location":"contents-tab/#content-tabs","title":"Content Tabs","text":"<p>This is some examples of content tabs.</p>"},{"location":"contents-tab/#generic-content","title":"Generic Content","text":"Plain textUnordered listOrdered list <p>This is some plain text</p> <ul> <li>First item</li> <li>Second item</li> <li>Third item</li> </ul> <ol> <li>First item</li> <li>Second item</li> <li>Third item</li> </ol>"},{"location":"contents-tab/#code-blocks-in-content-tabs","title":"Code Blocks in Content Tabs","text":"PythonJavaScript <pre><code>def main():\n    print(\"Hello world!\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>function main() {\n    console.log(\"Hello world!\");\n}\n\nmain();\n</code></pre>"},{"location":"diagram-examples/","title":"Diagram Examples","text":""},{"location":"diagram-examples/#flowcharts","title":"Flowcharts","text":"<pre><code>graph LR\n  A[Start] --&gt; B{Failure?};\n  B --&gt;|Yes| C[Investigate...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Success!];</code></pre>"},{"location":"diagram-examples/#sequence-diagrams","title":"Sequence Diagrams","text":"<pre><code>sequenceDiagram\n  autonumber\n  Server-&gt;&gt;Terminal: Send request\n  loop Health\n      Terminal-&gt;&gt;Terminal: Check for health\n  end\n  Note right of Terminal: System online\n  Terminal--&gt;&gt;Server: Everything is OK\n  Terminal-&gt;&gt;Database: Request customer data\n  Database--&gt;&gt;Terminal: Customer data</code></pre>"},{"location":"admin/manage-pdc/","title":"Manage Pentaho Data Catalog","text":""},{"location":"install/get-started/","title":"Get started with Pentaho Data Catalog","text":"<p>Before you use Pentaho Data Catalog, you must plan the data sources you want to add and the glossaries and terms it will use.</p> <p>You must first log in to Data Catalog using the credentials shared by your Data Catalog service user or site administrator. For information about logging into Data Catalog, see the Use Pentaho Data Catalog document.</p> <p>Next, view the following content to guide you through building and using Data Catalog.</p>"},{"location":"install/get-started/#plan-and-build-your-data-catalog","title":"Plan and build your Data Catalog","text":"<p>As a data steward, you can start planning and building Data Catalog for your data analysts to use.</p>"},{"location":"install/get-started/#planning-your-data-catalog","title":"Planning your Data Catalog","text":""},{"location":"install/hyperscalers/","title":"Hyperscalers","text":"<p>The advantage of using software in a hyperscale environment is that the architecture can scale as needed to meet increased usage by provisioning additional resources on demand. Hyperscale environments also offer full high availability, intelligent load balancing, and support for orchestration.</p> <p>You can use Pentaho Data Catalog in a hyperscaler environment by launching an instance of Data Catalog in the Amazon Web Services (AWS) Marketplace or the Microsoft Azure Marketplace.</p> <p>Launching a Data Catalog instance in a hyperscaler To launch an instance of Data Catalog in a hyperscaler, see the following procedures for the marketplace you want to use:</p>"},{"location":"install/hyperscalers/#launching-a-data-catalog-ami-in-aws","title":"Launching a Data Catalog AMI in AWS","text":"<p>You can launch a new Data Catalog Amazon Machine Image (AMI) from the AWS Marketplace. To use the Data Catalog AMI, you must create a customized security group and select or create an SSH key pair during the launch configuration.</p>"},{"location":"install/hyperscalers/#launch-the-data-catalog-ami-instance","title":"Launch the Data Catalog AMI instance","text":"<p>Perform the following steps to launch an instance of the Data Catalog AMI from the AWS console:</p> <p>Procedure</p> <ol> <li>From the AWS Console Home page, click EC2.</li> </ol> <p>The EC2 Dashboard opens with a Launch instance card.</p> <pre><code>!!! note\n    You can also launch a Data Catalog AMI from the Amazon Marketplace.\n</code></pre> <ol> <li> <p>On the Launch instance card, click Launch instance.</p> <p>The Launch an instance page opens.</p> </li> <li> <p>Add a name for the instance.</p> </li> <li>In the Application and OS images (Amazon Machine Image) card, enter Pentaho Data Catalog in the search field.</li> <li>On the Pentaho Data Catalog result, click Select.</li> <li>Review the product overview, details, and pricing, and click Continue to accept the terms.</li> <li> <p>On the Instance type card, choose an instance type from the list.</p> <p>For a Production environment, it is a best practice to use a 2xlarge or larger instance type.</p> </li> <li> <p>On the Key pair (login) card, select an existing key pair to connect securely, or create a new key pair.</p> <p>If you create a new private key, the file downloads automatically to your local computer.</p> <p>Note</p> <p>Make sure to store the private key file in a secure location, because you need it to connect to the instance using SSH.</p> </li> <li> <p>On the Network settings card, make the following selections:</p> <ul> <li>Under Firewall (security groups), select an existing security group or create a new one.</li> </ul> <p>Note</p> <p>Any existing security group you select must support SSH and HTTPS traffic.</p> <ul> <li>Select the Allow SSH traffic from checkbox and choose My IP from the list.</li> </ul> <p>Note</p> <p>Use the username pentaho and port 22 for SSH access.</p> <ul> <li>Select the Allow HTTPS traffic from the internet checkbox.</li> </ul> </li> <li> <p>On the Configure storage card, specify at least 512 GiB for a Production instance.</p> </li> <li> <p>Click Launch instance.</p> <p>The instance launches, and you are subscribed to the Marketplace AMI. When the process is complete, a success message includes a link to the instance, with the unique instance ID.</p> </li> <li> <p>Record the instance\u2019s IP address or URL.</p> <p>It is needed for the Set up an administrator account for the AWS instance procedure.</p> </li> <li> <p>Click the instance link.</p> <p>The Instances page opens.</p> </li> <li> <p>Select the checkbox next to the Data Catalog instance and click Launch instances.</p> </li> </ol> <p>Next Steps</p> <p>When the instance is running, you can connect to it using HTTPS in the browser on port 443. You might need to create a new rule or edit an existing rule to allow traffic on port 443 from your desired IP addresses or IP ranges.</p>"},{"location":"install/hyperscalers/#set-up-an-administrator-account-for-the-aws-instance","title":"Set up an administrator account for the AWS instance","text":"<p>You must set up an administrator account to manage your Data Catalog instance in the AWS Marketplace.</p> <p>Before you begin</p> <p>Before you begin this procedure, you must have an IP address or URL for accessing the Data Catalog instance and an environment that meets the following conditions:</p> <ul> <li>an active Data Catalog instance in the AWS Marketplace.</li> <li>traffic allowed on port 443 from your desired IP addresses or IP ranges.</li> </ul> <p>Perform the following steps to set up the account:</p> <p>Procedure</p> <ol> <li> <p>In a browser, navigate to the Data Catalog IP address or URL resulting from the Launch the Data Catalog AMI instance procedure.     You must use HTTPS to access the instance. You might see a NET::ERR_CERT_AUTHORITY_INVALID error message, due to Data Catalog's self-signed certificate.</p> </li> <li> <p>Ignore the error and proceed.     You can add your own certificates to Data Catalog later.     You are redirected to the Data Catalog admin account registration page.</p> </li> <li> <p>On the Create Admin Account page, provide details for the Data Catalog admin user and click Create Account. You are logged in to the admin account and see the Data Catalog home page.</p> </li> </ol> <p>Next Steps</p> <p>You can begin using Data Catalog or create accounts for other users in your organization.</p>"},{"location":"install/hyperscalers/#launching-a-data-catalog-vmi-in-azure","title":"Launching a Data Catalog VMI in Azure","text":"<p>You can launch a new Data Catalog Virtual Machine Image (VMI) from the Microsoft Azure Marketplace. To use the Data Catalog VMI, you must create a customized network security group and select or create an SSH key pair during the launch configuration.</p>"},{"location":"install/hyperscalers/#launch-the-data-catalog-vmi-instance","title":"Launch the Data Catalog VMI instance","text":""},{"location":"install/hyperscalers/#set-up-an-administrator-account-for-the-azure-instance","title":"Set up an administrator account for the Azure instance","text":""},{"location":"install/install-pdc/","title":"Installing Data Catalog","text":"<p>Tip</p> <p>It is a best practice before installing Data Catalog to save a copy of your conf/.env file to save any environment customizations you have made in case the file is overwritten during the installation process. During installation, Data Catalog checks for a PDC_DATA_ENCRYPTION_KEY environment variable in the conf/.env file. If the variable exists, the conf/.env file is retained. However, if the variable does not exist, Data Catalog generates a new .env file containing a PDC_DATA_ENCRYPTION_KEY environment variable. If needed, you can add any custom environment variable settings back in to the new .env file from your saved file.</p> <p>Perform the following steps to install Data Catalog:</p> <p>Before you begin</p> <p>Lorem ipsum</p> <p>Procedure</p> <ol> <li>Verify that you have root privileges or have the necessary permissions to run Docker.</li> <li>Open a terminal window on your dedicated Data Catalog deployment server.</li> <li>Save the Data Catalog release package in the Data Catalog server.</li> <li>Open a terminal window on your dedicated Data Catalog deployment server and extract the files from the release package to the /opt directory using the following command:     <pre><code>tar -xvf [name of release package].tar.gz -C /opt\n</code></pre>    The command creates a pentaho directory and extracts the contents of the deployment into a pdc-docker-deployment subdirectory.</li> <li>Load the required installation images that are packaged in the vendor directory into Docker using the following command:     <pre><code>cd /opt/pentaho/pdc-docker-deployment\n./pdc.sh load-images\n</code></pre>     You may get a message to set the <code>GLOBAL_SERVER_HOST_NAME</code> variable:     <pre><code>GLOBAL_SERVER_HOST_NAME env is not set, please select an environment variable value from the list or type your own:\n1.  IP address\n2.  Hostname\n3.  Hostname.localhost.localdomain\n4.  Other \n#?    1\n</code></pre></li> <li>(Optional) If you get the GLOBAL_SERVER_HOST_NAME env is not set message, enter the number for the option that you want to set as the variable and press Enter.     If you select 1, the script sets the GLOBAL_SERVER_HOST_NAME variable to the IP address in the conf/.env file.</li> <li> <p>Edit the conf/.env file to add email domains and keycloak SMTP configuration:     <pre><code>sudo vi conf/.env\n</code></pre>     a. Add new email allowed domains into the .env file. By default, Data Catalog includes users that use hv.com emails. You can add your own domain to this list:     <pre><code>EMAIL_DOMAINS='[\"hv.com\", \"hitachivantara.com\", \"pdccatalog.com\", \"example.com\", \"yahoo.com\"]'\n</code></pre>     b. Add configuration for Keycloak SMTP. In the example value below, SMTP configuration is set to use hv.com emails, but you can change these to point to your company\u2019s SMTP server configuration:     <pre><code>KEYCLOAK_SMTP='{\"replyToDisplayName\" : \"pdccatalog@hv.com\",\"starttls\" : \"true\",\"auth\" : \"true\",\"envelopeFrom\" : \"pdccatalog@hv.com\", \"ssl\" : \"true\",\"password\" : \"fwjx mpvb hcdb yofp\",\"port\" : \"465\",\"host\" : \"smtp.hv.com\",\"replyTo\" : \"pdccatalog@hv.com\",\"from\" : \"pdccatalog@hv.com\",\"fromDisplayName\" : \"pdccatalog@hv.com\",\"user\" : \"pdccatalog@hv.com\"}'\n</code></pre>    c. Save the file.</p> <p>Note</p> <p>The email and SMTP settings are complete. If you want to update email or SMTP settings after installation, this will need to be done using IAM APIs.</p> </li> <li> <p>Start all the Docker containers using the following command:     <pre><code>sh pdc.sh up\n</code></pre>     The installation script uses the packaged Docker images for the Data Catalog release and the Data Storage Optimizer release, if installed, to create and run Docker containers on your dedicated server.</p> </li> </ol> <p>Result</p> <p>The installation is ready for use after all the Docker containers have successfully started.</p>"},{"location":"install/requirements/","title":"Requirements","text":""},{"location":"install/requirements/#requirements","title":"Requirements","text":"<p>This article covers the installation of Pentaho Data Catalog. For every release, a release package containing all necessary Data Catalog software and dependencies for installation is made available.</p> <p>Note</p> <p>To access the appropriate release package, Hitachi Vantara provides specific credentials along with a URL download link. These credentials grant you access to download the required package for your server.</p> <p>Pentaho Data Catalog requires specific external components and applications to operate optimally. This article provides a list of those components and applications along with details of their use and the versions Data Catalog supports.</p>"},{"location":"install/requirements/#environment-considerations","title":"Environment considerations","text":"<p>To ensure proper software development and deployment practices, it is a best practice to have two separate environments:</p> <ul> <li>Development or Staging</li> <li>Production</li> </ul>"},{"location":"install/requirements/#system-requirements","title":"System requirements","text":"<p>This section outlines the software, hardware, and access requirements you should have before you install Data Catalog.</p> Checklist for infrastructure requests <p>Perform the following tasks as needed to prepare your environment for Data Catalog:</p> <ul> <li>Request a Virtual Machine (VM) on Azure or AWS or on-premises.</li> <li>Request IDs with remote access permissions to the VM on your cloud or on-premises.</li> <li>Request necessary access to systems, applications, and data sources.</li> <li>Request VDI or VPN access for Data Catalog data engineers to enable remote access to the VM.</li> <li>Request a database user account (service account) or logins for connecting to the data sources.</li> <li>Make sure the database user account has read-only permissions for the database objects, including system catalog tables.</li> <li>Make sure that your system owner or Database Administrator (DBA) has copied or extracted any required data or files.</li> <li>Obtain an SSL certificate from a certificate authority. If required by your organization's security policy, raise an infrastructure support request for an SSL certificate. The certificate authority will give you a key file and a certificate file.</li> </ul>"},{"location":"install/requirements/#hardware-requirements","title":"Hardware requirements","text":"<p>Your server and network must meet the following requirements:</p>"},{"location":"release-notes/overview/","title":"Overview","text":"<p>A modern organization must be data fit. As data volumes increase, so too does the necessity and cost of maintaining data in a state that is ready for business use. To harness data for business decisions and enable artificial intelligence, it is imperative that data is reliable, of high quality, and readily accessible to data users. The need to discover content across structured and unstructured formats, both on-premises and in the cloud, is more critical than ever. Organizations must continuously monitor their data to identify trends and anomalies and maintain data hygiene in tandem with data growth.</p> <p>Policies governing data lifecycle and quality must be enforced to ensure that high-quality data is available to consumers. Consequently, data users and models can efficiently locate and utilize data through the data catalog, which is essential for a modern data-driven organization.</p> <p>Pentaho Data Catalog swiftly ingests, profiles, and curates both structured and unstructured data utilizing automation and machine learning. Data and metadata fingerprinting rules are employed to contextualize data in the language of the business, as documented in the business glossary. The policy manager facilitates the implementation of governance and security policies.</p> <p>A robust rules engine determines quality, sensitivity, and usage patterns. Activate your metadata by leveraging Data Catalog monitoring and notification capabilities. Construct a relationship graph across business entities and terms to infuse semantic understanding into the data.</p> <p>Data fingerprints are analyzed to identify potential duplicates, copies, and similarities across data stores, thereby assessing data movement, optimization, and mastering needs. Data lineage support for Open Lineage enables tracking of data as it flows through the organization, fostering trust and facilitating early-stage data quality and remediation activities.</p> <p>An advanced observability stack captures popular assets, searches, and trends, enabling stewardship organizations to concentrate their efforts on pertinent data. Collaborate within the context of your data and business vocabulary to capture tribal knowledge, recommendations, and user perspectives on data assets.</p> <p>Documentation for this release is at the following link:</p>"},{"location":"release-notes/whats-new/","title":"What is new in Pentaho Data Catalog","text":""},{"location":"release-notes/whats-new/#key-features","title":"Key features","text":"<p>The key features in this release are:</p>"},{"location":"release-notes/whats-new/#data-delivery","title":"Data delivery","text":"<p>A business user is able to find data and with a few clicks be able to configure a data pipeline that delivers the data to its desired destination.</p>"},{"location":"release-notes/whats-new/#application-catalog","title":"Application catalog","text":"<p>Catalog your applications, their governance requirements, ownership, their relationship with data assets, reference data and other elements in the data catalog</p>"},{"location":"release-notes/whats-new/#governance-policies","title":"Governance policies","text":"<p>Document regulatory or corporate regulations, policies, standards in the catalog, building a source of record and an intuitive interface to find policies and the data to which they apply.</p>"},{"location":"release-notes/whats-new/#data-lineage","title":"Data lineage","text":"<p>Build data lineage for data movement executed by Pentaho ETL. Compatible with open lineage, this capability gives us a quick ROI for customers interested in lineage for Pentaho Data Integration.</p>"},{"location":"release-notes/whats-new/#galaxy-view","title":"Galaxy view","text":"<p>This release enhances the visual representation of assets (such as data assets, business terms, policies/standards/rules, reference data, and applications) to easily grasp the dependencies, understand potential impact, and collaborate with all the stakeholders to make the right business decision.</p>"},{"location":"release-notes/whats-new/#trust-score","title":"Trust score","text":"<p>Support for bringing data quality scores from the Pentaho Data Quality product, verification of lineage, and assessing sensitivity to build a trust score.</p>"},{"location":"release-notes/whats-new/#license-support","title":"License support","text":"<p>This release introduces a license solution for the Data Catalog and Pentaho Data Optimizer products. You can configure the number of data sources and Expert users (Steward, Admin, Developer) you can add, and the size of data scanned from file systems.</p> <p>In addition, there are numerous improvements including extensive rules support, additional support for data sources and technologies, and continued emphasis on ease of use and performance improvements.</p>"},{"location":"release-notes/whats-new/#product-roles-licensing","title":"Product roles &amp; licensing","text":"<p>Your Data Catalog software license determines the following entitlements:</p> <ul> <li>additional features that you can use (Pentaho Data Optimizer and Pentaho Data Mastering)</li> <li>the number of data sources you can add</li> <li>the amount of data you can scan</li> <li>the number of Expert user roles that you can assign to users. The Expert user roles are:<ul> <li>Business Steward</li> <li>Data Steward</li> <li>Admin</li> <li>Data Developer</li> </ul> </li> </ul> <p>To calculate the total number of users for licensing, use the following table for mapping from product role to licensing role. A named user with multiple product roles maps into a single user for licensing consideration. For example, if a user is given the role of data source administrator and data source access manager, that is considered a single licensed Data Steward. If two distinct users are given these two roles, then that is considered two licensed Data Stewards.</p> Product Roles Licensing Considerations Owner Admin User Reader Business User User Access Administrator Admin User Data Source Administrator Data Steward Data Source Access Manager Data Steward Data Quality Administrator Data Steward Data Quality Operator Data Steward Data Quality Rule Approver Data Steward Data Profiler Data Steward Data Sample Viewer Business User Data Tagger Data Steward Data Tag Viewer Data Steward Business Glossary Administrator Data Steward Business Glossary Mapper Data Steward Data Identification Methods Manager Data Steward Data Source Steward Data Steward"},{"location":"use/pdc-user-features/","title":"Data Catalog user features","text":""}]}